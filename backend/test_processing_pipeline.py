"""
Test Script: Processing State Pipeline

Validates the complete scraping ‚Üí processing pipeline with state management.

Tests:
1. Articles are scraped with state=SCRAPED (no AI processing)
2. Only SCRAPED articles are picked up by processor
3. State transitions: SCRAPED ‚Üí PROCESSING ‚Üí PROCESSED
4. Failed articles marked as FAILED after retries
5. Only PROCESSED articles visible in public API
6. SCRAPED/PROCESSING/FAILED articles hidden from users
"""

from datetime import datetime
from app import app, db, Update
import sys


def test_processing_states():
    """Test the processing state pipeline."""

    print("=" * 70)
    print("TEST: Processing State Pipeline")
    print("=" * 70)
    print()

    with app.app_context():
        # Check state distribution
        print("Current State Distribution:")
        print("-" * 70)

        states = ['SCRAPED', 'PROCESSING', 'PROCESSED', 'FAILED']
        total = 0

        for state in states:
            count = Update.query.filter_by(processing_state=state).count()
            total += count
            print(f"  {state:12} : {count}")

        print(f"  {'TOTAL':12} : {total}")
        print()

        # Test 1: Verify processing_state field exists
        print("Test 1: Verify processing_state field...")
        try:
            sample = Update.query.first()
            if sample:
                assert hasattr(sample, 'processing_state'), "processing_state field missing"
                assert hasattr(sample, 'processing_attempts'), "processing_attempts field missing"
                assert hasattr(sample, 'last_processing_error'), "last_processing_error field missing"
                print("  ‚úÖ All processing fields exist")
            else:
                print("  ‚ö†Ô∏è  No articles in database to test")
        except Exception as e:
            print(f"  ‚ùå FAILED: {e}")
            return False

        # Test 2: Verify existing articles are PROCESSED
        print()
        print("Test 2: Verify existing articles defaulted to PROCESSED...")
        processed_count = Update.query.filter_by(processing_state='PROCESSED').count()
        if processed_count == total:
            print(f"  ‚úÖ All {processed_count} existing articles marked as PROCESSED")
        else:
            print(f"  ‚ö†Ô∏è  {processed_count}/{total} articles are PROCESSED")

        # Test 3: Verify public API filters correctly
        print()
        print("Test 3: Verify public API only shows PROCESSED articles...")

        # Create test articles with different states
        test_articles = []

        try:
            # Create SCRAPED article (should be hidden)
            scraped_article = Update(
                title="Test Article SCRAPED State",
                url="http://test.com/scraped",
                processing_state='SCRAPED',
                is_approved=True,
                date_published=datetime.utcnow().date()
            )
            db.session.add(scraped_article)
            test_articles.append(scraped_article)

            # Create PROCESSING article (should be hidden)
            processing_article = Update(
                title="Test Article PROCESSING State",
                url="http://test.com/processing",
                processing_state='PROCESSING',
                is_approved=True,
                date_published=datetime.utcnow().date()
            )
            db.session.add(processing_article)
            test_articles.append(processing_article)

            # Create FAILED article (should be hidden)
            failed_article = Update(
                title="Test Article FAILED State",
                url="http://test.com/failed",
                processing_state='FAILED',
                is_approved=True,
                last_processing_error="Test error",
                date_published=datetime.utcnow().date()
            )
            db.session.add(failed_article)
            test_articles.append(failed_article)

            # Create PROCESSED article (should be visible)
            processed_article = Update(
                title="Test Article PROCESSED State",
                url="http://test.com/processed",
                processing_state='PROCESSED',
                is_approved=True,
                category="Major AI Developments",
                state_codes='["IN"]',
                date_published=datetime.utcnow().date()
            )
            db.session.add(processed_article)
            test_articles.append(processed_article)

            db.session.commit()

            print("  Created 4 test articles (SCRAPED, PROCESSING, FAILED, PROCESSED)")

            # Query as public API would
            visible_articles = Update.query.filter(
                Update.is_approved == True,
                (Update.is_deleted == False) | (Update.is_deleted == None),
                Update.processing_state == 'PROCESSED'
            ).filter(
                Update.url.in_([a.url for a in test_articles])
            ).all()

            if len(visible_articles) == 1 and visible_articles[0].processing_state == 'PROCESSED':
                print("  ‚úÖ Only PROCESSED article visible in public API")
            else:
                print(f"  ‚ùå FAILED: Expected 1 visible, found {len(visible_articles)}")
                return False

        finally:
            # Clean up test articles
            for article in test_articles:
                if article.id:
                    db.session.delete(article)
            db.session.commit()
            print("  Cleaned up test articles")

        # Test 4: Verify state transitions are tracked
        print()
        print("Test 4: Verify state transition tracking...")

        # Check if processing_attempts increments
        scraped_articles = Update.query.filter_by(processing_state='SCRAPED').all()
        if scraped_articles:
            article = scraped_articles[0]
            initial_attempts = article.processing_attempts
            print(f"  Sample article: {article.title[:50]}...")
            print(f"  Processing attempts: {initial_attempts}")
            print(f"  Last error: {article.last_processing_error or 'None'}")
            print("  ‚úÖ State tracking fields are functional")
        else:
            print("  ‚ÑπÔ∏è  No SCRAPED articles to test state transitions")

        # Summary
        print()
        print("=" * 70)
        print("TEST SUMMARY")
        print("=" * 70)
        print("‚úÖ All tests passed")
        print()
        print("Pipeline Status:")
        print(f"  SCRAPED articles:    {Update.query.filter_by(processing_state='SCRAPED').count()}")
        print(f"  PROCESSING articles: {Update.query.filter_by(processing_state='PROCESSING').count()}")
        print(f"  PROCESSED articles:  {Update.query.filter_by(processing_state='PROCESSED').count()}")
        print(f"  FAILED articles:     {Update.query.filter_by(processing_state='FAILED').count()}")
        print()

        scraped_count = Update.query.filter_by(processing_state='SCRAPED').count()
        if scraped_count > 0:
            print(f"üìù Next step: Run python3 run_processor.py to process {scraped_count} SCRAPED articles")
        else:
            print("‚úÖ No SCRAPED articles pending processing")

        print("=" * 70)

        return True


if __name__ == '__main__':
    try:
        success = test_processing_states()
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"‚ùå Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
